{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Introduction to Spark In-memory Computing via Python PySpark </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pyspark\n",
    "\n",
    "print(os.environ['SPARK_ROOT'])\n",
    "print(os.environ['SPARK_CONFIG_FILE'])\n",
    "print(os.environ['SPARK_ROOT'])\n",
    "print(os.environ['SPARK_MASTER_HOST'])\n",
    "print(os.environ['SPARK_MASTER_PORT'])\n",
    "print(os.environ['SPARK_MASTER_WEBUI_PORT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: spam filtering\n",
    "\n",
    "\n",
    "\n",
    "|     | viagra  | learning  | the | dating | prince | spam?   |\n",
    "| --- | ------- | --------- | --- | ------ | ------ | ------- | \n",
    "| X1  | 1       |  0        |  1  |  0     | 0      | Y1 = 1  |\n",
    "| X2  | 0       |  1        |  1  |  0     | 0      | Y2 = -1 | \n",
    "| X3  | 0       |  0        |  0  |  0     | 1      | Y3 = 1  |\n",
    "\n",
    "\n",
    "- Instance spaces X1, X2, X3 belong to set X (data points)\n",
    "  - Binary or real-valued feature vector X of word occurrences\n",
    "  - `d` features (words and other things, d is approximately 100,000)\n",
    "- Class Y\n",
    "  - Spam = 1\n",
    "  - Ham  = -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    " \n",
    "- Originally developed by Vapnik and collaborators as a linear classifier.\n",
    "- Could be modified to support non-linear classification by mapping into high-dimensional spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example\n",
    "\n",
    "- https://spark.apache.org/docs/2.4.5/api/python/pyspark.mllib.html#pyspark.mllib.classification.SVMModel\n",
    "- https://spark.apache.org/docs/2.4.5/mllib-data-types.html#labeled-point\n",
    "- https://spark.apache.org/docs/2.4.5/api/python/pyspark.sql.html#pyspark.sql.DataFrame (look for randomSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import SVMWithSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    LabeledPoint(0.0, [0.0]),\n",
    "    LabeledPoint(1.0, [1.0]),\n",
    "    LabeledPoint(1.0, [2.0]),\n",
    "    LabeledPoint(1.0, [3.0])\n",
    "]\n",
    "svm = SVMWithSGD.train(sc.parallelize(data), iterations=10)\n",
    "svm.predict([1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Can you predict whether a client will subscribe to a term deposit (feature deposit)?\n",
    "\n",
    "### Problems:\n",
    "- What data should the bank data be converted to?\n",
    "- How to handle categorical data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('bank.csv', header = True, inferSchema = True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_deposit = df.select('deposit').distinct().collect()\n",
    "print(unique_deposit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('marital').distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we want all columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we build categorical data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_dictionary = {}\n",
    "cat_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'day', 'month', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit']\n",
    "\n",
    "for c in cat_columns:\n",
    "    unique_c = df.select(c).distinct().collect()\n",
    "    #print(c + \": \" + str(len(unique_c)))\n",
    "    cat_dictionary[c] = {}\n",
    "    i = 0\n",
    "    for v in unique_c:\n",
    "        cat_dictionary[c][v[c]] = i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate LabelPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPrep(r):\n",
    "    key = 0\n",
    "    value = []\n",
    "    for c in columns:\n",
    "        if c == 'deposit':\n",
    "            key = cat_dictionary[c][r[columns.index(c)]]\n",
    "        else:\n",
    "            if c in cat_columns:\n",
    "                value.append(cat_dictionary[c][r[columns.index(c)]])\n",
    "            else:\n",
    "                value.append(r[columns.index(c)])\n",
    "    return LabeledPoint(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPrep(df.rdd.take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.rdd.map(dataPrep)\n",
    "df_clean.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_svm = df_clean.randomSplit([0.8, 0.2], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean.count())\n",
    "print(df_svm[0].count())\n",
    "print(df_svm[1].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_bank = SVMWithSGD.train(df_svm[0], iterations=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def testPrediction(p):\n",
    "    prediction = svm_bank.predict(p.features)\n",
    "    if prediction == p.label:\n",
    "        return (\"correct\", 1)\n",
    "    else:\n",
    "        return (\"incorrect\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_svm[1].map(testPrediction).reduceByKey(lambda x, y: x + y)\n",
    "df_results.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "- To be completed at home\n",
    "- Can you change the column combinations to make this prediction better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
